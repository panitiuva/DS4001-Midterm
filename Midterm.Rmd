---
title: "Package Presentation: tidytext"
author: "Paniti Mongkonpathumrat"
date: "9/29/2020"
output:
  html_document:
    toc: TRUE
    theme: darkly
    toc_float: TRUE
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=F, warning = FALSE, error = FALSE, message = FALSE, cache = TRUE)
```

```{r, out.width='30%', fig.align='center', fig.cap=""}
knitr::include_graphics('C:/Users/66971/Desktop/3 fall/DS 4001/midterm/tidytext_pic.png')
```
[picture's reference link](https://cran.r-project.org/web/packages/tidytext/readme/README.html)

---

## Package Overview{.tabset}

```{r, out.width='100%', fig.align='center', fig.cap=""}
knitr::include_graphics('C:/Users/66971/Desktop/3 fall/DS 4001/midterm/tidyflow-ch-1.png')
```
[picture's reference link](https://www.tidytextmining.com/tidytext.html#fig:tidyflow-ch1)

### Problem
It took much effort to clean data and many methods aren’t applicable to text. This package is intended to facilitate text analysis tasks with more effectiveness and consistency with tidy tools. It helps to convert text to and from tidy formats, and to switch between tidy tools and existing text analysis packages.

### Version history
The latest version I can find is 0.2.6, and there are 16 others versions from 0.1.0 to 0.2.5. 

### Usage
It can be installed by
```{r, echo=T, eval=F}
install.packages("tidytext")
# or
library(remotes)
install_github("juliasilge/tidytext")
```

Then, it can be used in these steps of sentiment analysis:

* restructure text as one-token-per-row format by tokenization
* remove stop words
* word count
* get sentiment of tokens
* visualize the result

Also, it is useful in lots of other text analysis, such as topic modeling.

* tidy corpus
* create tdm
* tidy tdm
* tidy LDA result

### Dependency

* R (≥ 2.10)
* other text mining package such as tm and quanteda

Also, these package are included and are needed for text mining:

* dplyr 
* broom
* tidyr
* ggplot2

We use these packages with tidytext because we are working on tidy text dataset and visualizing the result is helpful for analysis. 

---

## Examples of Usage
There are two parts I would like to introduce here: sentiment analysis and topic modeling

In the overview of sentiment analysis, I will use this following text to explain each function used in each step of basic sentiment analysis.
```{r, echo=T}
text <- c("How many loved your moments of glad grace -",
          "And loved your beauty with love false or true -",
          "But one man loved the pilgrim soul in you -",
          "And loved the sorrows of your changing face")

text # poem by WILLIAM BUTLER YEATS
```
[poem's reference link](https://www.poetryfoundation.org/poems/43283/when-you-are-old)

In the part of topic modeling, I will use a text data from BBC articles in business topic.

Reference: D. Greene and P. Cunningham. "Practical Solutions to the Problem of Diagonal Dominance in Kernel Document Clustering", Proc. ICML 2006.

---

### Functions in sentiment analysis{.tabset}

#### unnest_tokens
This function will split the table created from the text data into words, called "tokens", using the tokenizers package and arrange them into one token per row. 

Then, I have to put the text into a data frame first.
```{r, echo=T}
library(dplyr)
text_df <- tibble(line = 1:4, text = text)

text_df
```

Then, we can convert this data frame to one-token-per-row structure by using unnest_tokens. The first argument is the name of the output column I want the text to be in (word) while the second argument is the name of the input column that the text comes from (text). Also, the argument to_lower indicates the output characteristics whether it should be lowercase or not.

```{r, echo=T}
library(tidytext)

tidy_books <- text_df %>%
  unnest_tokens(word, text, to_lower = T)

tidy_books
```

Note

* Punctuation has been stripped.

---

#### anti_join & stop_words
This function with the data set stop_words from the package will delete the stop words that are not useful for analysis, such as, “the”, “of”, and “to”. The reason of this process is that these words are not useful in the text analysis. 

```{r, echo=T}
data(stop_words)

tidy_books <- tidy_books %>%
  anti_join(stop_words)
```

---

#### count
This function is in dplyr, but it is a useful step in text mining. It will show the word count of each word in the text

```{r, echo=T}
tidy_books %>%
  count(word, sort = TRUE) 
```

---

#### get_sentiments 
This function is used to get specific sentiment lexicons of each token in a tidy format. In this case, I use bing as the lexicon. 

```{r, echo=T}
get_sentiments(lexicon = c("bing")) # "afinn", "loughran", "nrc"
```

Then, I can use these sentiments to match with each word in my text.

```{r, echo=T}
poemsentiment <- tidy_books %>%
  inner_join(get_sentiments("bing"), by = "word")

poemsentiment
```

Note

* Finally, the result is usually displayed in graphic by using ggplot. However, it is not the main feature of this package.

---

### Functions in topic modeling {.tabset}

#### corpus_tidiers & tidy.Corpus
corpus_tidiers change format of a corpus object from the quanteda package into a tidy format, while tidy.Corpus does the same thing but it is used for a corpus object from the tm package.

This is an example of tidy format of a corpus from BBC articles in business topic.
```{r}
library(readtext)
wd <- "C:/Users/66971/Desktop/3 fall/STAT 4559/Homework 2/bbc-fulltext/bbc"
textdf_bus <- readtext(paste0(wd,"/business/*"), encoding = "UTF-8")

library(quanteda)
textcorpus <- corpus(textdf_bus$text)
```

```{r, echo=T}
textcorpus_tidy <- tidy(textcorpus)
head(textcorpus_tidy)
```

Note

* Corpus is an unstructured set of texts.

---

#### cast_tdm & tdm_tidiers
cast_tdm changes a data frame to a DocumentTermMatrix or dtm.

tdm_tidiers changes a DocumentTermMatrix into a tidy format of a three-column data frame showing the documents, each word in each document, and the numbers of appearance.

This is also an example of tidy format of a tdm from BBC articles in business topic.
```{r}
library(tm)
tmcorpus_bus <- Corpus(VectorSource(textdf_bus$text))
DTM <- DocumentTermMatrix(tmcorpus_bus)
```

```{r, echo=T}
DTM_tidy <- tidy(DTM)
head(DTM_tidy, 10)
```

Note

* dtms are sparse matrices that usually have document on each row and word or token in each column. It is a very useful format in topic modeling and some other text analysis.

---

#### lda_tidiers
This function tidies the results of a Latent Dirichlet Allocation (LDA). LDA is a method to create a topic model that is similar to clustering analysis, but for text or words. It helps to separate document or text into topics. However, this function does not conduct the Latent Dirichlet Allocation itself. It just changes the format of the result, so that it is easier to use tidy tools in furthur analysis. 

This is also an example of tidy format of the result from using lda on BBC articles in business topic.
```{r}
library(topicmodels)

text_lda <- LDA(DTM, k = 2, method = "VEM", control = NULL)
```

```{r, echo=T}
text_topics_tidy <- tidy(text_lda, matrix = "beta") ## per-topic-per-word probabilities
head(text_topics_tidy, 10)
```

Note

* beta is per-topic-per-word probability

---

## Similar Packages
### quanteda
Quantitative text analysis is the purpose of creating this package while tidytext focus more on visualization. It was developed by Kenneth Benoit and other contributors. The main difference as mentioned above is the ability to create a corpus. quanteda also includes a range of functions from basic to more advanced statistical analysis such as wordscores by textmodel_wordscores() and wordfish by textmodel_wordfish() which are not included in tidytext. However, there are some functions in common, such as, text tokenization and document-feature matrix creation.

### tm
Again, the main difference is that tm works on the corpus structure organizing text as a collection of documents. On the other hand, tidytext works on tidy text structure. Therefore, tm has an ability to create a corpus while tidytext does not. They also have the same basic functions like text tokenization and document-feature matrix creation.

---

## Reflection{.tabset}

### Pros
Mainly, it solves the problem of many methods not applicable to text. For those who get used to tidyverse, it works very well with tidy tools such as dplyr or tidyr. It also works well with ggplot2 to visualize the result. 

### Cons
I think the disadvantage is mainly the inability to create corpus. Most of the feature of tidytext is to convert other structures into tidy format, so another disadvantage is also tidy. Personally, I get more used to base R than to tidy. Therefore, tidytext is only helpful for users familiar with the tidyverse.

---

## Reference

*  [Text Mining with R](https://sloanreview.mit.edu/article/the-recessions-impact-on-analytics-and-data-science/)
*  [RDocument](https://www.rdocumentation.org/packages/tidytext/versions/0.2.5#:~:text=tidytext%3A%20Text%20mining%20using%20tidy%20tools&text=Using%20tidy%20data%20principles%20can,%2C%20broom%2C%20tidyr%20and%20ggplot2.)
*  [cran.r-project](https://cran.r-project.org/web/packages/tidytext/index.html)
*  [quanteda](https://quanteda.io/articles/pkgdown/comparison.html)
*  [towardsdatascience](https://towardsdatascience.com/r-packages-for-text-analysis-ad8d86684adb)
*  [seanwarlick](https://www.seanwarlick.com/post/2017-07-11-comparing-tm-and-tidytext/#:~:text=The%20corpus%20structure%20organizes%20text,frame%20as%20the%20data%20structure.)
*  [topic modeling](https://www.tidytextmining.com/topicmodeling.html)

---

